{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for event_id, hits, cells, particles, truth in load_dataset('../storage/track_ml_data/train_5.zip'):\n",
    "    if cnt == 4:\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for event_id, hits, cells, particles, truth in load_dataset('../storage/track_ml_data/train_5.zip'):\n",
    "    if cnt == 5:\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for event_id, hits, cells, particles, truth in load_dataset('../storage/track_ml_data/train_sample.zip'):\n",
    "    print(event_id)\n",
    "    if cnt == 50:\n",
    "        break\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import hdbscan\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "class Clusterer(object):\n",
    "    def __init__(self,rz_scales=[0.65, 0.965, 1.528]):                        \n",
    "        self.rz_scales=rz_scales\n",
    "    \n",
    "    def _eliminate_outliers(self,labels,M):\n",
    "        norms=np.zeros((len(labels)),np.float32)\n",
    "        indices=np.zeros((len(labels)),np.float32)\n",
    "        for i, cluster in tqdm(enumerate(labels),total=len(labels)):\n",
    "            if cluster == 0:\n",
    "                continue\n",
    "            index = np.argwhere(self.clusters==cluster)\n",
    "            index = np.reshape(index,(index.shape[0]))\n",
    "            indices[i] = len(index)\n",
    "            x = M[index]\n",
    "            norms[i] = self._test_quadric(x)\n",
    "        threshold1 = np.percentile(norms,90)*5\n",
    "        threshold2 = 25\n",
    "        threshold3 = 6\n",
    "        for i, cluster in enumerate(labels):\n",
    "            if norms[i] > threshold1 or indices[i] > threshold2 or indices[i] < threshold3:\n",
    "                self.clusters[self.clusters==cluster]=0   \n",
    "    def _test_quadric(self,x):\n",
    "        if x.size == 0 or len(x.shape)<2:\n",
    "            return 0\n",
    "        xm = np.mean(x,axis=0)\n",
    "        x = x - xm\n",
    "        Z = np.zeros((x.shape[0],10), np.float32)\n",
    "        Z[:,0] = x[:,0]**2\n",
    "        Z[:,1] = 2*x[:,0]*x[:,1]\n",
    "        Z[:,2] = 2*x[:,0]*x[:,2]\n",
    "        Z[:,3] = 2*x[:,0]\n",
    "        Z[:,4] = x[:,1]**2\n",
    "        Z[:,5] = 2*x[:,1]*x[:,2]\n",
    "        Z[:,6] = 2*x[:,1]\n",
    "        Z[:,7] = x[:,2]**2\n",
    "        Z[:,8] = 2*x[:,2]\n",
    "        Z[:,9] = 1\n",
    "        v, s, t = np.linalg.svd(Z,full_matrices=False)        \n",
    "        smallest_index = np.argmin(np.array(s))\n",
    "        T = np.array(t)\n",
    "        T = T[smallest_index,:]        \n",
    "        norm = np.linalg.norm(np.dot(Z,T), ord=2)**2\n",
    "        return norm\n",
    "\n",
    "    def _preprocess(self, hits):\n",
    "        \n",
    "        x = hits.x.values\n",
    "        y = hits.y.values\n",
    "        z = hits.z.values\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2 + z**2)\n",
    "        hits['x2'] = x/r\n",
    "        hits['y2'] = y/r\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        hits['z2'] = z/r\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        X = ss.fit_transform(hits[['x2', 'y2', 'z2']].values)\n",
    "        for i, rz_scale in enumerate(self.rz_scales):\n",
    "            X[:,i] = X[:,i] * rz_scale\n",
    "       \n",
    "        return X\n",
    "    \n",
    "    \n",
    "    \n",
    "    def find_labels(self, params):\n",
    "        w1, w2, w3, w4, w5, w6, w7, epsilon = 2.7474448671796874,1.3649721713529086,0.7034918842926337,\\\n",
    "                                0.0005549122352940002,0.023096034747190672,0.04619756315527515,\\\n",
    "                                0.2437077420144654,0.009750302717746615\n",
    "        \n",
    "        hits, dz, z_shift, unroll_type = params\n",
    "\n",
    "        hits['z'] = hits['z'] - z_shift\n",
    "        hits['r'] = np.sqrt(hits['x'].values ** 2 + hits['y'].values ** 2 + hits['z'].values ** 2)\n",
    "        hits['rt'] = np.sqrt(hits['x'].values ** 2 + hits['y'].values ** 2)\n",
    "        hits['a0'] = np.arctan2(hits['y'].values, hits['x'].values)\n",
    "        hits['z1'] = hits['z'].values / hits['rt'].values\n",
    "        hits['z2'] = hits['z'].values / hits['r'].values\n",
    "        hits['s1'] = hits['hit_id']\n",
    "        hits['N1'] = 1\n",
    "        hits['z1'] = hits['z'].values / hits['rt'].values\n",
    "        hits['z2'] = hits['z'].values / hits['r'].values\n",
    "        hits['x1'] = hits['x'].values / hits['y'].values\n",
    "        hits['x2'] = hits['x'].values / hits['r'].values\n",
    "        hits['x3'] = hits['y'].values / hits['r'].values\n",
    "        hits['x4'] = hits['rt'].values / hits['r'].values\n",
    "       \n",
    "        #hits['a1'] = hits['a0'].values + np.nan_to_num(np.arccos(dz*hits['rt'].values))\n",
    "\n",
    "        if unroll_type == 0:\n",
    "            hits['a1'] = hits['a0'].values + np.nan_to_num(np.arccos(dz*hits['rt'].values))\n",
    "        if unroll_type == 1:\n",
    "            hits['a1'] = hits['a0'].values + dz*hits['rt'].values\n",
    "        if unroll_type == 2:\n",
    "            hits['a1'] = hits['a0'].values + dz*hits['z'].values\n",
    "        if unroll_type == 3:\n",
    "            hits['a1'] = hits['a0'].values + dz * (hits['rt'].values + 0.000005 * hits['rt'].values ** 2)\n",
    "        #hits['a1'] = hits['a0'].values + np.nan_to_num(np.arccos(dz*hits['rt'].values))\n",
    "\n",
    "        hits['sina1'] = np.sin(hits['a1'].values)\n",
    "        hits['cosa1'] = np.cos(hits['a1'].values)\n",
    "        ss = StandardScaler()\n",
    "        hits = ss.fit_transform(hits[['sina1', 'cosa1', 'z1', 'z2','x1','x2','x3','x4']].values)\n",
    "        cx = np.array([w1, w1, w2, w3, w4, w5, w6, w7])\n",
    "        hits = np.multiply(hits, cx)\n",
    "        clusters = DBSCAN(eps=0.009750302717746615, min_samples=1, metric=\"euclidean\", n_jobs=32).fit(hits).labels_\n",
    "        return clusters    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _init(self, hits, Niter):\n",
    "        \n",
    "#         w1, w2, w3, w4, w5, w6, w7, epsilon = 2.7474448671796874,1.3649721713529086,0.7034918842926337,\\\n",
    "#                                         0.0005549122352940002,0.023096034747190672,0.04619756315527515,\\\n",
    "#                                         0.2437077420144654,0.009750302717746615\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        params = []\n",
    "        for i in range(Niter):\n",
    "            \n",
    "            unroll_type = np.random.randint(0,4)\n",
    "            if unroll_type == 0:\n",
    "                dz = np.random.normal(0.0, 0.00035)\n",
    "            elif unroll_type == 1:\n",
    "                dz = np.random.normal(0.0, 0.00065)\n",
    "            elif unroll_type == 2:\n",
    "                dz = np.random.normal(0.0, 0.00085)\n",
    "            elif unroll_type == 3:\n",
    "                dz = np.random.normal(0.0, 0.001)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            #dz = 1 / 1000 * (ii / 2) / 180 * np.pi\n",
    "            #dz = np.random.normal(0.0, 0.001)\n",
    "            #dz = np.random.normal(0.0, 0.00035)\n",
    " \n",
    "            z_shift = np.random.normal(0.0, 4.5)\n",
    "\n",
    "\n",
    "            params.append((hits, dz, z_shift, unroll_type))\n",
    "            \n",
    "        pool = Pool(processes=8)\n",
    "        result = []\n",
    "        for i in tqdm(pool.imap(self.find_labels, params)):\n",
    "            result += [i]\n",
    "        pool.close()\n",
    "                \n",
    "            \n",
    "        return np.array(result)\n",
    "    \n",
    "    def predict(self, hits, Niter):         \n",
    "        result  = self._init(hits, Niter)\n",
    "#         X = self._preprocess(hits) \n",
    "#         cl = hdbscan.HDBSCAN(min_samples=1,min_cluster_size=7,\n",
    "#                              metric='braycurtis',cluster_selection_method='leaf',algorithm='best', leaf_size=50)\n",
    "#         labels = np.unique(self.clusters)\n",
    "#         self._eliminate_outliers(labels,X)          \n",
    "#         max_len = np.max(self.clusters)\n",
    "#         mask = self.clusters == 0\n",
    "#         self.clusters[mask] = cl.fit_predict(X[mask])+max_len\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    pickle.dump([1, 2], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002949606435870417"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 1000 * (338 / 2) / 180 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:59,  5.24it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "951it [02:55,  5.41it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "2238it [06:54,  5.40it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "3000it [09:16,  5.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Clusterer()\n",
    "result = model.predict(hits, 3000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1671it [06:29,  4.29it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "2076it [07:58,  4.34it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "3000it [11:22,  4.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Clusterer()\n",
    "result = model.predict(hits, 3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "665it [02:21,  4.70it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "865it [03:01,  4.76it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "2409it [08:09,  4.92it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "2509it [08:29,  4.92it/s]/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:96: RuntimeWarning: invalid value encountered in arccos\n",
      "3000it [10:10,  4.91it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Clusterer()\n",
    "result = model.predict(hits, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(cl1, cl2, min_cnt): # merge cluster 2 to cluster 1\n",
    "    d = pd.DataFrame(data={'s1':cl1,'s2':cl2})\n",
    "    d['N1'] = d.groupby('s1')['s1'].transform('count')\n",
    "    d['N2'] = d.groupby('s2')['s2'].transform('count')\n",
    "    maxs1 = d['s1'].max()\n",
    "    cond = np.where((d['N2'].values>d['N1'].values) & (d['N2'].values<20) &  (d['N2'].values>min_cnt))\n",
    "    #cond = np.where((d['N2'].values>d['N1'].values) & (d['N2'].values<20) )\n",
    "\n",
    "    s1 = d['s1'].values \n",
    "    s1[cond] = d['s2'].values[cond]+maxs1 \n",
    "    return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.vstack([result, result0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "result0 =result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.linalg.svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predicts/luis_3', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predicts/luis_4', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predicts/luis_5', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5922888474688374\n"
     ]
    }
   ],
   "source": [
    "#result = np.array(second)\n",
    "labels = range(result.shape[1])\n",
    "\n",
    "for k in [0]:\n",
    "    for i in range(len(result[:])):\n",
    "        labels = merge(labels, result[i], k)\n",
    "\n",
    "    submission = create_one_event_submission(0, hits['hit_id'].values, labels)\n",
    "    print(score_event(truth, submission))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6103758646010513\n",
    "0.5986615684933159\n",
    "0.597\n",
    "0.44631528825442496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5071140015567802\n"
     ]
    }
   ],
   "source": [
    "submission = create_one_event_submission(0, hits['hit_id'].values, labels)\n",
    "score = score_event(truth, submission)\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5071140015567802\n",
    "0.5022115428740757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('predicts/luis_all_1000_event', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 125504)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
